{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jesteban247/Procesamiento-Datos/blob/main/SparkSQL_corrige.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBcWjhOZbfaL"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.0.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version\n",
        "\n",
        "\n",
        "import pyspark\n",
        "import random\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark SQL demo\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"Initialization successful\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRBxYQqLbfaP"
      },
      "source": [
        "# Spark SQL\n",
        "\n",
        "**Spark SQL API reference:** https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAOQOly3bfaP"
      },
      "source": [
        "\n",
        "<ul>\n",
        "<li> <b>Spark SQL</b>: interface for working with structured and semi-structured data in Spark.\n",
        "<li> Load data from structured sources (JSON, Hive, Parquet, Cassandra...)\n",
        "<li> Query data using SQL.\n",
        "<li> Mix SQL and Python/Java/Scala code.\n",
        "<li> Spark SQL + <b>DataFrames</b>\n",
        "</ul>\n",
        "</div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx9-OwUlbfaT"
      },
      "source": [
        "# Reading Structured Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEAG3di4dXKy"
      },
      "source": [
        "!wget -q https://gquercini.github.io/courses/plp/tutorials/moviesEmbedded.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJDKvq49bfaT"
      },
      "source": [
        "movies_data = spark.read.json(\"./moviesEmbedded.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcGmXRMhbfaW"
      },
      "source": [
        "# Displays the content of the DataFrame to stdout\n",
        "movies_data.show(vertical=True, truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH-_oElZbfaY"
      },
      "source": [
        "# Print the schema in a tree format\n",
        "movies_data.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT0Lztbjbfab"
      },
      "source": [
        "## Get data from a Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb7GYAjqbfab"
      },
      "source": [
        "# Select only the \"name\" column\n",
        "movies_data.select(\"title\").show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKDzwajAbfae"
      },
      "source": [
        "title_and_country = movies_data.select(\"title\", \"country\")\n",
        "title_and_country.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QwfxtpMbfag"
      },
      "source": [
        "french_movies = title_and_country.filter(title_and_country['country']=='FR')\n",
        "french_movies.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJzAywKVbfai"
      },
      "source": [
        "french_movies.rdd.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TDhHIP_bfak"
      },
      "source": [
        "# french_movies est un DataFrame\n",
        "# my_french_movies est un RDD\n",
        "my_french_movies = french_movies.rdd.map(lambda x: (x.title, x.country))\n",
        "# Le r√©sultat de la collect() est bien une liste Python.\n",
        "l = my_french_movies.collect()\n",
        "print(l[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tOxb1Dpbfam"
      },
      "source": [
        "my_french_movies = my_french_movies.mapValues(lambda x: \"France\")\n",
        "my_french_movies.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqx33mRbbfap"
      },
      "source": [
        "# movies_data est un DataFrame.\n",
        "movies_by_country = movies_data.groupBy(\"country\").count()\n",
        "movies_by_country.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djh9_5RBbfar"
      },
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "movies_by_country = movies_by_country.sort(col(\"count\").desc())\n",
        "movies_by_country.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpC6GJJGbfau"
      },
      "source": [
        "# Querying Data with SQL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvV2Ytlwbfav"
      },
      "source": [
        "# Register the DataFrame as a SQL temporary view\n",
        "movies_data.createOrReplaceTempView(\"movies_embedded\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTgvJVGqbfax"
      },
      "source": [
        "movies_by_country = spark.sql('''\n",
        "            SELECT country, count(*) as nbMovies\n",
        "            FROM movies_embedded\n",
        "            GROUP BY country\n",
        "            ORDER BY nbMovies DESC''')\n",
        "movies_by_country.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DZ1Hh67bfaz"
      },
      "source": [
        "countries = movies_by_country.first()[0]\n",
        "print(countries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bax6o5eObfa1"
      },
      "source": [
        "countries = movies_by_country.first().country\n",
        "print(countries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxdTcKEVbfa3"
      },
      "source": [
        "<h2>Exercice: Normalizing the dataset</h2>\n",
        "\n",
        "<p>\n",
        "<div class=\"prez\">\n",
        "<ul>\n",
        " <li> We have one table <b>movies_embedded</b> that contain the information about the movies\n",
        "        and also includes the information about the actors and directors.\n",
        "<li> In relational databases parlance the table <b>movies_embedded</b> is not in first normal form.\n",
        "</ul>\n",
        "\n",
        "We intend here to normalize this table by breaking it into several tables:\n",
        "\n",
        "<ul>\n",
        "<li> A table <b>movies</b> containing: _id, title, year, genre, summary, country\n",
        "<li>A table <b>artists</b>  containing: _id, first_name, last_name, birth_date\n",
        "<li> A table <b>movies_actors</b> containing: _id_movie, _id_actor, role\n",
        "<li> A table <b>movies_directors</b> containing: _id_movie, _id_director\n",
        "</ul>\n",
        "\n",
        "<div>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv1GvSoIbfa3"
      },
      "source": [
        "## Create the table movies\n",
        "\n",
        "\n",
        "* Create a new dataframe `movies_table` from the dataframe `movies_data`.\n",
        "\n",
        "* In the process, rename the column `_id` as `movie_id`.\n",
        "\n",
        "* By using the function `createOrReplaceTempView`, create a new view `movies`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQnbX4ULbfa4"
      },
      "source": [
        "movies_table = movies_data\\\n",
        "  .select(\"_id\", \"title\", \"year\", \"genre\", \"summary\", \"country\")\\\n",
        "  .withColumnRenamed(\"_id\", \"movie_id\")\n",
        "movies_table.show()\n",
        "movies_table.createOrReplaceTempView(\"movies\")\n",
        "\n",
        "# Another possibility:\n",
        "#movies_table = movies_data.selectExpr(\"_id as movie_id\", \"title\", \\\n",
        "#                                      \"year\", \"genre\", \"summary\", \"country\")\n",
        "#movies_table.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnic1P4KbfbB"
      },
      "source": [
        "## Create the table movies_actors\n",
        "\n",
        "From the dataframe `movies_data`, create a new dataframe `movies_actors`, where each row contains a mapping between a movie and an actor.\n",
        "Also, create a view `movies_actors` from this dataframe.\n",
        "\n",
        "**HINT.** In the dataframe `movies_data`, the information about the actors of a film are embedded into a list. We need to take the actors out this list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0ymDBvRbfbC"
      },
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "movies_actors = movies_data\\\n",
        "      .select(\"_id\", F.explode(\"actors\").alias(\"actor\"))\\\n",
        "      .selectExpr(\"_id as movie_id\", \"actor._id as actor_id\", \"actor.role as actor_role\" )\n",
        "\n",
        "movies_actors.show(vertical=False, truncate=False)\n",
        "movies_actors.createOrReplaceTempView(\"movies_actors\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzgahPB3bfbO"
      },
      "source": [
        "## Create the table movies_directors\n",
        "\n",
        "From the dataframe `movies_data`, create a new dataframe `movies_directors`, where each row contains a mapping between a movie and a director.\n",
        "Also, create a view `movies_directors` from this dataframe.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH_wfDhRbfbQ"
      },
      "source": [
        "movies_directors = movies_data.selectExpr(\"_id as movie_id\",\n",
        "                                          \"director._id as director_id\")\n",
        "movies_directors.show()\n",
        "movies_directors.createOrReplaceTempView(\"movies_directors\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ax0DbVvjbfbS"
      },
      "source": [
        "## Create table artists\n",
        "\n",
        "From the dataframe `movies_data`, create a new dataframe `artists` that contain the information about actors and directors.\n",
        "Also, create a view `artists` from this dataframe.\n",
        "\n",
        "**HINT.** First obtain a dataframe `actors`, then a dataframe `directors` and finally compute the union of the two dataframes. Make sure that the dataframe `artists` does not contain any duplicates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OgVxzSGbfbS"
      },
      "source": [
        "actors = movies_data.select(F.explode(\"actors\").alias(\"actor\"))\\\n",
        "    .selectExpr(\"actor._id as artist_id\", \\\n",
        "                \"actor.first_name as first_name\", \\\n",
        "                \"actor.last_name as last_name\",\n",
        "               \"actor.birth_date as birth_date\")\n",
        "\n",
        "directors = movies_data.select(\"director\")\\\n",
        "    .selectExpr(\"director._id as artist_id\", \\\n",
        "                \"director.first_name as first_name\", \\\n",
        "                \"director.last_name as last_name\",\n",
        "               \"director.birth_date as birth_date\")\n",
        "\n",
        "artists = actors.union(directors).distinct()\n",
        "artists.show()\n",
        "artists.createOrReplaceTempView(\"artists\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qISwBM6KbfbU"
      },
      "source": [
        "## Querying the new collection of data\n",
        "\n",
        "Write a SQL query to count the number of movies for each artist. Sort the artists so that the one with the most movies appears as the first result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3af_o2QIbfbV"
      },
      "source": [
        "spark.sql(\"SELECT a.artist_id, a.first_name, a.last_name, count(*) as nb_movies\\\n",
        "             FROM movies m JOIN movies_actors ma USING(movie_id) JOIN artists a \\\n",
        "                ON a.artist_id=ma.actor_id \\\n",
        "             GROUP BY a.artist_id, a.first_name, a.last_name \\\n",
        "             ORDER BY nb_movies DESC\").show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIbuzh_kbfbW"
      },
      "source": [
        "## Writing the new tables to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ_fpjT6bfbX"
      },
      "source": [
        "movies_table.write.json(\"movies_table.json\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}